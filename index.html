<!DOCTYPE html>
<html>
<head>
  <title>Sukothai Generator</title>
</head>
<body>
  <h1>Sukothai Generator</h1>
  <p>Create a Sukothai-style composition using an audio file or recording.</p>
  
  <div>
    <h3>Choose Input Method</h3>
    <div>
      <input type="radio" name="inputMethod" id="fileMethod" value="file" checked>
      <label for="fileMethod">Upload</label>
      <input type="file" id="fileInput" accept="audio/*">
    </div>
    
    <div>
      <input type="radio" name="inputMethod" id="recordMethod" value="record">
      <label for="recordMethod">Record</label>
      <span id="recordingControls" hidden>
        <button id="recordButton">Start Recording</button>
        <span id="recordingTime">00:00</span>
      </span>
    </div>
  </div>
<br>
  <div>
    <label for="maxLayers">Maximum Number of Layers:</label>
    <select id="maxLayers">
      <option value="0">1 layer</option>
      <option value="1">2 layers</option>
      <option value="2">4 layers</option>
      <option value="3">8 layers</option>
      <option value="4">16 layers</option>
      <option value="5">32 layers</option>
      <option value="6">64 layers</option>
      <option value="7">128 layers</option>
      <option value="8">256 layers</option>
      <option value="9">512 layers</option>
      <option value="10" selected>1024 layers</option>
      <option value="11">2048 layers</option>
      <option value="12">4096 layers</option>
    </select>
  </div>
<br>
  <div>
    <button id="startButton" disabled>Start</button>
    <button id="stopButton" disabled>Stop</button>
  </div>
<br>
  <div id="status">Ready to start</div>

  <script>
    const INITIAL_VOLUME = 1.0;
    const BASE_DELAY = 100;
    const DELAY_VARIATION = 5;
    
    let audioContext;
    let sourceBuffer;
    let currentGeneration = 0;
    let isPlaying = false;
    let activeSources = [];
    let nextGenerationTimeout;
    let mediaRecorder;
    let recordedChunks = [];
    let isRecording = false;
    let recordingStartTime;
    let recordingTimer;

    document.getElementById('startButton').addEventListener('click', startPiece);
    document.getElementById('stopButton').addEventListener('click', stopPiece);
    
    document.querySelectorAll('input[name="inputMethod"]').forEach(radio => {
      radio.addEventListener('change', (e) => {
        document.getElementById('fileInput').hidden = e.target.value !== 'file';
        document.getElementById('recordingControls').hidden = e.target.value !== 'record';
      });
    });

    document.getElementById('recordButton').addEventListener('click', toggleRecording);

    async function toggleRecording() {
      if (!isRecording) {
        try {
          if (!audioContext) {
            audioContext = new AudioContext();
          }
          
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          mediaRecorder = new MediaRecorder(stream);
          recordedChunks = [];
          
          mediaRecorder.ondataavailable = (e) => {
            if (e.data.size > 0) {
              recordedChunks.push(e.data);
            }
          };
          
          mediaRecorder.onstop = async () => {
            const blob = new Blob(recordedChunks, { type: 'audio/webm' });
            const arrayBuffer = await blob.arrayBuffer();
            sourceBuffer = await audioContext.decodeAudioData(arrayBuffer);
            
            document.getElementById('startButton').disabled = false;
            document.getElementById('status').textContent = 'Recording ready - starting composition';
            startPiece();
          };
          
          mediaRecorder.start();
          isRecording = true;
          recordingStartTime = Date.now();
          updateRecordingTime();
          document.getElementById('recordButton').textContent = 'Stop Recording';
          document.getElementById('status').textContent = 'Recording...';
          
        } catch (err) {
          console.error('Error accessing microphone:', err);
          document.getElementById('status').textContent = 'Error accessing microphone';
        }
      } else {
        mediaRecorder.stop();
        mediaRecorder.stream.getTracks().forEach(track => track.stop());
        isRecording = false;
        clearInterval(recordingTimer);
        document.getElementById('recordButton').textContent = 'Start Recording';
      }
    }

    function updateRecordingTime() {
      clearInterval(recordingTimer);
      recordingTimer = setInterval(() => {
        const elapsed = Date.now() - recordingStartTime;
        const seconds = Math.floor(elapsed / 1000);
        const minutes = Math.floor(seconds / 60);
        const remainingSeconds = seconds % 60;
        document.getElementById('recordingTime').textContent = 
          `${minutes.toString().padStart(2, '0')}:${remainingSeconds.toString().padStart(2, '0')}`;
      }, 1000);
    }

    document.getElementById('fileInput').addEventListener('change', async (e) => {
      const file = e.target.files[0];
      if (!file) return;

      if (!audioContext) {
        audioContext = new AudioContext();
      }

      try {
        const arrayBuffer = await file.arrayBuffer();
        sourceBuffer = await audioContext.decodeAudioData(arrayBuffer);
        document.getElementById('startButton').disabled = false;
        document.getElementById('status').textContent = 'Sample loaded - ready to start';
      } catch (err) {
        console.error('Error loading audio:', err);
        document.getElementById('status').textContent = 'Error loading audio file';
      }
    });

    async function startPiece() {
      if (!sourceBuffer || isPlaying) return;
      
      isPlaying = true;
      currentGeneration = 0;
      document.getElementById('startButton').disabled = true;
      document.getElementById('stopButton').disabled = false;
      
      await playGeneration();
    }

    async function playGeneration() {
      const maxGenerations = parseInt(document.getElementById('maxLayers').value);
      
      if (!isPlaying || currentGeneration > maxGenerations) {
        stopPiece();
        return;
      }

      const numLayers = Math.pow(2, currentGeneration);
      document.getElementById('status').textContent = 
        `Playing generation ${currentGeneration + 1}/${maxGenerations + 1} (${numLayers} layers)`;

      const layerPromises = [];
      for (let i = 0; i < numLayers; i++) {
        layerPromises.push(createLayer(i, numLayers));
      }

      await Promise.all(layerPromises);

      nextGenerationTimeout = setTimeout(() => {
        currentGeneration++;
        playGeneration();
      }, sourceBuffer.duration * 1000 + 500);
    }

    async function createLayer(index, totalLayers) {
      const source = audioContext.createBufferSource();
      const gainNode = audioContext.createGain();
      
      source.buffer = sourceBuffer;
      
      const gainReduction = 1 / Math.sqrt(Math.pow(2, currentGeneration));
      gainNode.gain.value = INITIAL_VOLUME * gainReduction;

      const randomVariation = (Math.random() * 2 - 1) * DELAY_VARIATION;
      const delay = (BASE_DELAY + randomVariation) * index / 1000;

      source.connect(gainNode);
      gainNode.connect(audioContext.destination);
      
      source.start(audioContext.currentTime + delay);
      activeSources.push(source);
      source.stop(audioContext.currentTime + delay + sourceBuffer.duration);
    }

    function stopPiece() {
      isPlaying = false;
      
      activeSources.forEach(source => {
        try {
          source.stop();
        } catch (e) {
          // Ignore already stopped sources
        }
      });
      activeSources = [];
      
      if (nextGenerationTimeout) {
        clearTimeout(nextGenerationTimeout);
      }
      
      document.getElementById('startButton').disabled = false;
      document.getElementById('stopButton').disabled = true;
      document.getElementById('status').textContent = 'Stopped';
      
      currentGeneration = 0;
    }
  </script>
</body>
</html>
